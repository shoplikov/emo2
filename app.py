import streamlit as st
import cv2
import torch
import pandas as pd
import numpy as np
from ultralytics import YOLO
from transformers import AutoImageProcessor, AutoModelForImageClassification
from PIL import Image
import os
import tempfile
import base64
from pathlib import Path
import io

# Configure page
st.set_page_config(
    page_title="Video Emotion Analysis & Review",
    page_icon="ðŸŽ­",
    layout="wide"
)

# Initialize session state
if 'page' not in st.session_state:
    st.session_state.page = 'processing'
if 'processed_csv' not in st.session_state:
    st.session_state.processed_csv = None
if 'video_path' not in st.session_state:
    st.session_state.video_path = None
if 'review_data' not in st.session_state:
    st.session_state.review_data = None
if 'current_transition' not in st.session_state:
    st.session_state.current_transition = 0

# Emotion detection code
@st.cache_resource
def load_models():
    """Load YOLO face detection and emotion classification models"""
    try:
        yolo = YOLO('models/yolov12n-face.pt')
        processor = AutoImageProcessor.from_pretrained("trpakov/vit-face-expression")
        expr_model = AutoModelForImageClassification.from_pretrained("trpakov/vit-face-expression")
        return yolo, processor, expr_model
    except Exception as e:
        st.error(f"Error loading models: {str(e)}")
        return None, None, None

def detect_face(yolo_model, frame):
    """Detect face in frame and return cropped face image"""
    results = yolo_model.predict(
        source=frame,
        conf=0.25,
        imgsz=1280,
        line_width=1,
        max_det=1,
        verbose=False
    )
    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy()
        if len(boxes) == 0:
            return None
        x1, y1, x2, y2 = boxes[0]
        w, h = x2 - x1, y2 - y1
        expand_ratio = 0.1
        x1e = max(0, int(x1 - w * expand_ratio))
        y1e = max(0, int(y1 - h * expand_ratio))
        x2e = min(frame.width, int(x2 + w * expand_ratio))
        y2e = min(frame.height, int(y2 + h * expand_ratio))
        face_img = frame.crop((x1e, y1e, x2e, y2e))
        return face_img
    return None

def predict_expression(processor, expr_model, face_img):
    """Predict emotion from face image"""
    inputs = processor(images=face_img, return_tensors="pt")
    with torch.no_grad():
        outputs = expr_model(**inputs)
    probs = outputs.logits.softmax(dim=1)
    pred = probs.argmax(dim=1).item()
    label = expr_model.config.id2label[pred]
    return label

def process_video(video_path, yolo_model, processor, expr_model, step_sec=1.0, output_csv='output.csv', progress_bar=None):
    """Process video and generate emotion transitions CSV"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    results = []
    cur_time = 0.0
    
    prev_emotion = None
    segment_start = 0.0
    
    total_steps = int(duration / step_sec)
    step = 0
    
    while cur_time < duration:
        frame_idx = int(cur_time * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            break
        
        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        face_img = detect_face(yolo_model, pil_img)
        
        if face_img is not None:
            emotion = predict_expression(processor, expr_model, face_img)
        else:
            emotion = "no_face"
        
        if prev_emotion is None:
            prev_emotion = emotion
            segment_start = cur_time
        elif emotion != prev_emotion:
            results.append({
                'time_from': round(segment_start, 2),
                'time_to': round(cur_time, 2),
                'emotion_from': prev_emotion,
                'emotion_to': emotion
            })
            segment_start = cur_time
            prev_emotion = emotion
        
        cur_time += step_sec
        step += 1
        
        if progress_bar:
            progress_bar.progress(min(step / total_steps, 1.0))
    
    if prev_emotion is not None and segment_start < duration:
        results.append({
            'time_from': round(segment_start, 2),
            'time_to': round(duration, 2),
            'emotion_from': prev_emotion,
            'emotion_to': prev_emotion
        })
    
    cap.release()
    df = pd.DataFrame(results)
    df.to_csv(output_csv, index=False)
    return df

def extract_frame_at_time(video_path, time_sec):
    """Extract frame from video at specific time"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_idx = int(time_sec * fps)
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
    ret, frame = cap.read()
    cap.release()
    if ret:
        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    return None

def extract_video_clip(video_path, start_time, end_time, output_path):
    """Extract video clip between timestamps"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    start_frame = int(start_time * fps)
    end_frame = int(end_time * fps)
    
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, 
                         (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 
                          int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))
    
    current_frame = start_frame
    while current_frame < end_frame:
        ret, frame = cap.read()
        if not ret:
            break
        out.write(frame)
        current_frame += 1
    
    cap.release()
    out.release()

def video_processing_page():
    """Page 1: Video Processing"""
    st.title("ðŸŽ­ ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ¼Ð¾Ñ†Ð¸Ð¹ Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾")
    st.markdown("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²")
    
    # File uploader
    uploaded_file = st.file_uploader(
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹: MP4, AVI, MOV, MKV"
    )
    
    if uploaded_file is not None:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            video_path = tmp_file.name
            st.session_state.video_path = video_path
        
        # Display video info
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps
        cap.release()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ", f"{duration:.2f} ÑÐµÐº")
        with col2:
            st.metric("ÐšÐ°Ð´Ñ€Ð¾Ð² Ð² ÑÐµÐºÑƒÐ½Ð´Ñƒ", f"{fps:.2f}")
        with col3:
            st.metric("Ð’ÑÐµÐ³Ð¾ ÐºÐ°Ð´Ñ€Ð¾Ð²", frame_count)
        
        # Processing parameters
        st.subheader("ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸")
        step_sec = st.slider("Ð˜Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð°Ð½Ð°Ð»Ð¸Ð·Ð° (ÑÐµÐºÑƒÐ½Ð´Ñ‹)", 0.5, 5.0, 1.0, 0.5)
        
        # Process button
        if st.button("ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾", type="primary"):
            with st.spinner("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹..."):
                yolo_model, processor, expr_model = load_models()
                
            if yolo_model is None:
                st.error("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.")
                return
            
            # Process video with progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            status_text.text("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð¸Ð´ÐµÐ¾...")
            
            try:
                # Create temporary CSV file
                csv_path = tempfile.mktemp(suffix='.csv')
                
                df = process_video(
                    video_path, yolo_model, processor, expr_model, 
                    step_sec=step_sec, output_csv=csv_path, progress_bar=progress_bar
                )
                
                st.session_state.processed_csv = csv_path
                status_text.text("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°!")
                
                # Display results summary
                st.subheader("ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Ð’ÑÐµÐ³Ð¾ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²", len(df))
                
                with col2:
                    unique_emotions = set(df['emotion_from'].tolist() + df['emotion_to'].tolist())
                    st.metric("Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ¼Ð¾Ñ†Ð¸Ð¹", len(unique_emotions))
                
                # Display CSV preview
                st.subheader("ðŸ“‹ ÐŸÑ€ÐµÐ´Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð² ÑÐ¼Ð¾Ñ†Ð¸Ð¹")
                st.dataframe(df, use_container_width=True)
                
                # Download CSV
                csv_buffer = io.StringIO()
                df.to_csv(csv_buffer, index=False)
                st.download_button(
                    label="ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ CSV",
                    data=csv_buffer.getvalue(),
                    file_name=f"emotion_transitions_{uploaded_file.name}.csv",
                    mime="text/csv"
                )
                
                # Button to go to review page
                if st.button("âž¡ï¸ ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ðº Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ", type="primary"):
                    st.session_state.page = 'review'
                    st.rerun()
                    
            except Exception as e:
                st.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð²Ð¸Ð´ÐµÐ¾: {str(e)}")
                status_text.text("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ!")

def review_interface_page():
    """Page 2: Review Interface"""
    st.title("âœ… ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð² ÑÐ¼Ð¾Ñ†Ð¸Ð¹")
    
    if st.session_state.processed_csv is None:
        st.warning("ÐÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð¹Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾.")
        if st.button("â† ÐÐ°Ð·Ð°Ð´ Ðº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ"):
            st.session_state.page = 'processing'
            st.rerun()
        return
    
    # Load review data
    if st.session_state.review_data is None:
        df = pd.read_csv(st.session_state.processed_csv)
        # Add review columns
        df['review'] = 'pending'
        df['reviewed_emotion_from'] = ''
        df['reviewed_emotion_to'] = ''
        df['comment'] = ''
        st.session_state.review_data = df
    
    df = st.session_state.review_data
    current_idx = st.session_state.current_transition
    
    if len(df) == 0:
        st.warning("ÐÐµÑ‚ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð² Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸.")
        return
    
    # Progress indicator
    st.progress((current_idx + 1) / len(df))
    st.markdown(f"**ÐŸÐµÑ€ÐµÑ…Ð¾Ð´ {current_idx + 1} Ð¸Ð· {len(df)}**")
    
    # Current transition data
    row = df.iloc[current_idx]
    
    # Display transition info
    st.subheader(f"ÐŸÐµÑ€ÐµÑ…Ð¾Ð´: {row['emotion_from']} â†’ {row['emotion_to']}")
    st.markdown(f"**Ð’Ñ€ÐµÐ¼Ñ:** Ñ {row['time_from']}Ñ Ð¿Ð¾ {row['time_to']}Ñ")
    
    # Create columns for frames (wider for better visibility)
    col1, col2 = st.columns([2, 2])

    with col1:
        st.markdown("**ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ°Ð´Ñ€**")
        start_frame = extract_frame_at_time(st.session_state.video_path, row['time_from'])
        if start_frame is not None:
            st.image(start_frame, caption=f"Ð’ {row['time_from']}Ñ", use_container_width=True)
        else:
            st.info("ÐÐµÑ‚ ÐºÐ°Ð´Ñ€Ð° Ð´Ð»Ñ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸.")

    with col2:
        st.markdown("**ÐšÐ¾Ð½ÐµÑ‡Ð½Ñ‹Ð¹ ÐºÐ°Ð´Ñ€**")
        end_frame = extract_frame_at_time(st.session_state.video_path, row['time_to'])
        if end_frame is not None:
            st.image(end_frame, caption=f"Ð’ {row['time_to']}Ñ", use_container_width=True)
        else:
            st.info("ÐÐµÑ‚ ÐºÐ°Ð´Ñ€Ð° Ð´Ð»Ñ ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ð³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸.")

    st.divider()

    # Review controls
    st.subheader("ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð°")
    st.markdown("ÐžÐ´Ð¾Ð±Ñ€Ð¸Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´, ÐµÑÐ»Ð¸ Ð¾Ð½ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚ÐµÐ½, Ð¸Ð»Ð¸ Ð¾Ñ‚ÐºÐ»Ð¾Ð½Ð¸Ñ‚Ðµ Ð¸ Ð²Ð½ÐµÑÐ¸Ñ‚Ðµ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ.")

    # Show current review status
    if row['review'] != 'pending':
        status_color = "ðŸŸ¢" if row['review'] == 'approved' else "ðŸ”´"
        st.markdown(f"**Ð¡Ñ‚Ð°Ñ‚ÑƒÑ:** {status_color} {row['review'].title()}")
        if row['reviewed_emotion_from'] or row['reviewed_emotion_to']:
            st.markdown(f"**Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¾:** {row['reviewed_emotion_from']} â†’ {row['reviewed_emotion_to']}")
        if row['comment']:
            st.markdown(f"**ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹:** {row['comment']}")

    # Review buttons
    col1, col2 = st.columns([1, 1])

    with col1:
        if st.button("âœ… ÐžÐ´Ð¾Ð±Ñ€Ð¸Ñ‚ÑŒ", type="primary", use_container_width=True, help="ÐžÑ‚Ð¼ÐµÑ‚Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´ ÐºÐ°Ðº ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹"):
            df.loc[current_idx, 'review'] = 'approved'
            st.session_state.review_data = df
            if current_idx < len(df) - 1:
                st.session_state.current_transition += 1
            st.rerun()

    with col2:
        if st.button("âŒ ÐžÑ‚ÐºÐ»Ð¾Ð½Ð¸Ñ‚ÑŒ", use_container_width=True, help="ÐžÑ‚Ð¼ÐµÑ‚Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´ ÐºÐ°Ðº Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð¸ Ð²Ð½ÐµÑÑ‚Ð¸ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ"):
            df.loc[current_idx, 'review'] = 'rejected'
            st.session_state.review_data = df
            st.session_state.show_correction = True
            st.rerun()

    # Correction interface
    if row['review'] == 'rejected' or st.session_state.get('show_correction', False):
        st.subheader("Ð˜Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ")
        st.markdown("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ¼Ð¾Ñ†Ð¸Ð¸ Ð¸ Ð´Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸.")

        emotion_options = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

        col1, col2 = st.columns(2)
        with col1:
            corrected_from = st.selectbox(
                "Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÑÐ¼Ð¾Ñ†Ð¸Ñ (Ð¾Ñ‚):",
                options=[''] + emotion_options,
                index=0 if not row['reviewed_emotion_from'] else emotion_options.index(row['reviewed_emotion_from']) + 1
            )

        with col2:
            corrected_to = st.selectbox(
                "Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÑÐ¼Ð¾Ñ†Ð¸Ñ (Ðº):",
                options=[''] + emotion_options,
                index=0 if not row['reviewed_emotion_to'] else emotion_options.index(row['reviewed_emotion_to']) + 1
            )

        comment = st.text_area("ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹:", value=row['comment'], help="ÐÐµÐ¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾: Ð´Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÑŽ.")

        if st.button("ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ", help="Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð²Ð°ÑˆÐ¸ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð°"):
            df.loc[current_idx, 'reviewed_emotion_from'] = corrected_from
            df.loc[current_idx, 'reviewed_emotion_to'] = corrected_to
            df.loc[current_idx, 'comment'] = comment
            st.session_state.review_data = df
            st.session_state.show_correction = False
            st.success("Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾!")
            # Go to next transition if not last
            if current_idx < len(df) - 1:
                st.session_state.current_transition += 1
            st.rerun()

    st.divider()

    # Navigation
    st.subheader("ÐÐ°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ñ")
    col1, col2, col3 = st.columns([1, 2, 1])

    with col1:
        if st.button("â¬…ï¸ ÐŸÑ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹", disabled=(current_idx == 0), help="Ðš Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¼Ñƒ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ñƒ"):
            st.session_state.current_transition = max(0, current_idx - 1)
            st.rerun()

    with col2:
        jump_to = st.number_input("ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ðº Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ñƒ:", min_value=1, max_value=len(df), value=current_idx + 1, help="Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð°") - 1
        if jump_to != current_idx:
            st.session_state.current_transition = jump_to
            st.rerun()

    with col3:
        if st.button("âž¡ï¸ Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹", disabled=(current_idx == len(df) - 1), help="Ðš ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¼Ñƒ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ñƒ"):
            st.session_state.current_transition = min(len(df) - 1, current_idx + 1)
            st.rerun()

    st.divider()

    # Export final CSV
    st.subheader("Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²")
    st.markdown("Ð¡ÐºÐ°Ñ‡Ð°Ð¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ñ‹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ CSV.")

    approved = len(df[df['review'] == 'approved'])
    rejected = len(df[df['review'] == 'rejected'])
    pending = len(df[df['review'] == 'pending'])

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("âœ… ÐžÐ´Ð¾Ð±Ñ€ÐµÐ½Ð¾", approved)
    with col2:
        st.metric("âŒ ÐžÑ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¾", rejected)
    with col3:
        st.metric("â³ Ð’ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ð¸", pending)

    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False)
    st.download_button(
        label="ðŸ“¥ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ CSV",
        data=csv_buffer.getvalue(),
        file_name="reviewed_emotion_transitions.csv",
        mime="text/csv",
        type="primary"
    )

    if st.button("â† ÐÐ°Ð·Ð°Ð´ Ðº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ", help="Ð’ÐµÑ€Ð½ÑƒÑ‚ÑŒÑÑ Ðº ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð²Ð¸Ð´ÐµÐ¾"):
        st.session_state.page = 'processing'
        st.session_state.processed_csv = None
        st.session_state.review_data = None
        st.session_state.current_transition = 0
        st.rerun()

# Main app
def main():
    # Sidebar navigation
    st.sidebar.title("ÐÐ°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ñ")
    
    if st.sidebar.button("ðŸ“¹ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð¸Ð´ÐµÐ¾", use_container_width=True):
        st.session_state.page = 'processing'
    
    if st.sidebar.button("âœ… ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²", use_container_width=True):
        st.session_state.page = 'review'
    
    # Page routing
    if st.session_state.page == 'processing':
        video_processing_page()
    elif st.session_state.page == 'review':
        review_interface_page()

if __name__ == "__main__":
    main()